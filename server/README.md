# Server - Chatbots PDF Reader

API REST do projeto Chatbots PDF Reader.

## üöÄ Tecnologias

- **Node.js** com TypeScript
- **Fastify** - Framework web r√°pido e eficiente
- **Drizzle ORM** - ORM TypeScript-first
- **PostgreSQL** com pgvector - Banco de dados com suporte a embeddings vetoriais
- **Ollama** - IA para embedding de PDFs, tradu√ß√£o de texto e gera√ß√£o de respostas
- **LangChain** - Text splitters para processamento de PDFs
- **pdf.js** - Extra√ß√£o de texto de PDFs
- **Zod** - Valida√ß√£o de schemas
- **Biome**/**Ultracite** - Linter e formatter

## üìã Pr√©-requisitos

- Node.js 20+
- Docker e Docker Compose
- npm, yarn ou pnpm
- Ollama instalado localmente

## ‚öôÔ∏è Setup e Configura√ß√£o

### 1. Instalar depend√™ncias

```bash
npm install
```

### 2. Configurar vari√°veis de ambiente

Copie o arquivo de exemplo:

```bash
cp .env.example .env
```

### 3. Instalar Ollama e baixar modelos

Fa√ßa download do Ollama em [https://ollama.com/](https://ollama.com/) e adicione os modelos:

```bash
ollama pull llama3.1
ollama pull nomic-embed-text
```

> ‚ö†Ô∏è **Nota:** O modelo [llama3.1](https://ollama.com/library/llama3.1) requer mais recursos de hardware. Se enfrentar problemas de desempenho, considere usar o [llama3.2](https://ollama.com/library/llama3.2), uma vers√£o mais leve, por√©m com capacidades reduzidas. Neste caso, lembre-se de atualizar as vari√°veis `TRANSLATION_MODEL` e `ANSWER_QUESTION_MODEL` no arquivo `.env` para `llama3.2`.

### 4. Iniciar o banco de dados

Execute o PostgreSQL com Docker:

```bash
docker-compose up -d
```

### 5. Gerar e executar migrations

```bash
npm run db:generate
npm run db:migrate
```

### 6. (Opcional) Popular o banco com dados de exemplo

```bash
npm run db:seed
```

### 7. Iniciar o servidor

Modo desenvolvimento:

```bash
npm run dev
```

Modo produ√ß√£o:

```bash
npm start
```

O servidor estar√° rodando em `http://localhost:3333`

## üìù Scripts Dispon√≠veis

- `npm run dev` - Inicia o servidor em modo desenvolvimento com watch mode
- `npm start` - Inicia o servidor em modo produ√ß√£o
- `npm run db:generate` - Gera migrations baseadas nas mudan√ßas do schema
- `npm run db:migrate` - Executa as migrations pendentes no banco de dados
- `npm run db:seed` - Popula o banco de dados com dados de exemplo

## üîß Padr√µes de Projeto

- **Type-safe API** - Uso de Zod com Fastify para valida√ß√£o de tipos em runtime
- **Snake case** - Conven√ß√£o de nomenclatura para colunas do banco de dados (via Drizzle)
- **Repository Pattern** - Schemas do Drizzle organizados por entidade na pasta `db/schema/`
- **Service Layer** - L√≥gica de neg√≥cio isolada em services (AI providers, etc.)

## Perguntas

### Por que escolheu os modelos "llama3.1" e "nomic-embed-text"?

O **llama3.1** √© um modelo de linguagem poderoso e vers√°til, ideal para tradu√ß√£o de textos e gera√ß√£o de respostas contextualizadas. O **nomic-embed-text** √© especializado em gerar embeddings de alta qualidade para busca sem√¢ntica, sendo otimizado para textos em ingl√™s e portugu√™s.

### Qual estrat√©gia de RAG foi implementado?

A implementa√ß√£o segue o padr√£o cl√°ssico de RAG:

1. **Chunking**: O PDF √© dividido em chunks menores usando LangChain text splitters
2. **Embedding**: Gera embeddings vetoriais de cada chunk usando o modelo `nomic-embed-text`
3. **Armazenamento**: Os embeddings s√£o salvos no PostgreSQL com extens√£o pgvector
4. **Retrieval**: Quando uma pergunta √© feita:
   - Gera o embedding da pergunta
   - Faz busca de similaridade vetorial no banco
   - Recupera os chunks mais relevantes
5. **Generation**: Envia os chunks relevantes + pergunta para o LLM (`llama3.1`) gerar a resposta contextualizada

### Arquitetura e decis√µes t√©cnicas?

**Por que Fastify ao inv√©s de NestJS?**

- ‚úÖ **Performance**: Fastify √© um dos frameworks Node.js mais r√°pidos
- ‚úÖ **Simplicidade**: Ideal para APIs pequenas e m√©dias sem complexidade desnecess√°ria
- ‚úÖ **Overhead m√≠nimo**: Setup r√°pido e bundle menor
- ‚úÖ **Ecossistema**: Plugins maduros e bem mantidos

NestJS seria overkill para este projeto porque adiciona camadas de abstra√ß√£o desnecess√°rias para um escopo simples. NestJS √© mais adequado para projetos corporativos grandes com m√∫ltiplos m√≥dulos.

**Por que Drizzle ORM?**

- ‚úÖ **Type-safety total** com TypeScript
- ‚úÖ **SQL-like syntax**: Mant√©m voc√™ pr√≥ximo ao SQL real, ajudando a n√£o esquecer a linguagem
- ‚úÖ **Leve e perform√°tico**: N√£o adiciona overhead como outros ORMs pesados
- ‚úÖ **Migrations simples**: F√°cil gerenciamento com Drizzle Kit
- ‚úÖ **Portabilidade**: Facilita mudan√ßa entre bancos de dados

A escolha de um ORM acelera o desenvolvimento e aumenta a manutenibilidade do c√≥digo.

### Quais melhorias posso fazer com mais tempo?

**1. Autentica√ß√£o JWT** (Impacto: Alto | Complexidade: M√©dia)
- Implementar endpoints de login e cadastro
- Adicionar autentica√ß√£o com JWT usando `@fastify/jwt`
- Criar tabela `users` e proteger rotas
- Associar chatbots aos usu√°rios logados

**2. Listagem e Gerenciamento de PDFs** (Impacto: Alto | Complexidade: Baixa)
- Modificar endpoint `GET /chatbots/:id` para incluir lista de PDFs enviados
- Criar endpoint `DELETE /chatbots/:id/files/:fileId` para remover PDFs
- Melhorar visualiza√ß√£o dos documentos vinculados

**3. Busca H√≠brida (Vetorial + Full-Text)** (Impacto: Alto | Complexidade: Alta)
- Combinar busca vetorial (sem√¢ntica) com busca Full-Text (palavras-chave)
- Pondera√ß√£o entre busca sem√¢ntica (70%) e keyword (30%)
- Melhor captura de termos t√©cnicos espec√≠ficos
- Adicionar √≠ndice GIN no PostgreSQL para otimiza√ß√£o
  